(450, 512, 512, 1) (450, 512, 512, 1)
(113, 512, 512, 1) (113, 512, 512, 1)
(141, 512, 512, 1) (141, 512, 512, 1)
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 512, 512, 1)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 512, 512, 16)      160       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 256, 256, 16)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 256, 256, 32)      4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 128, 128, 32)      0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 128, 128, 64)      18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 64, 64, 64)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 64, 64, 128)       73856     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 32, 32, 128)       0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 32, 32, 256)       295168    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 16, 16, 256)       0         
_________________________________________________________________
dense_1 (Dense)              (None, 16, 16, 512)       131584    
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 32, 32, 512)       0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 32, 32, 256)       1179904   
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 64, 64, 256)       0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 64, 64, 128)       295040    
_________________________________________________________________
up_sampling2d_3 (UpSampling2 (None, 128, 128, 128)     0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 128, 128, 64)      73792     
_________________________________________________________________
up_sampling2d_4 (UpSampling2 (None, 256, 256, 64)      0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 256, 256, 32)      18464     
_________________________________________________________________
up_sampling2d_5 (UpSampling2 (None, 512, 512, 32)      0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 512, 512, 1)       289       
=================================================================
Total params: 2,091,393
Trainable params: 2,091,393
Non-trainable params: 0
_________________________________________________________________
Train on 450 samples, validate on 113 samples
Epoch 1/100
 - 12s - loss: -3.9616e-01 - dice_coef: 0.3969 - val_loss: -4.1437e-01 - val_dice_coef: 0.4162
Epoch 2/100
 - 6s - loss: -5.0308e-01 - dice_coef: 0.5042 - val_loss: -5.9373e-01 - val_dice_coef: 0.5955
Epoch 3/100
 - 7s - loss: -5.9595e-01 - dice_coef: 0.5954 - val_loss: -6.1027e-01 - val_dice_coef: 0.6121
Epoch 4/100
 - 6s - loss: -6.1246e-01 - dice_coef: 0.6125 - val_loss: -6.2287e-01 - val_dice_coef: 0.6246
Epoch 5/100
 - 7s - loss: -6.1650e-01 - dice_coef: 0.6165 - val_loss: -6.2233e-01 - val_dice_coef: 0.6241
Epoch 6/100
 - 7s - loss: -6.0553e-01 - dice_coef: 0.6068 - val_loss: -6.1607e-01 - val_dice_coef: 0.6176
Epoch 7/100
 - 7s - loss: -6.1932e-01 - dice_coef: 0.6191 - val_loss: -6.2830e-01 - val_dice_coef: 0.6299
Epoch 8/100
 - 7s - loss: -6.2359e-01 - dice_coef: 0.6241 - val_loss: -6.3034e-01 - val_dice_coef: 0.6319
Epoch 9/100
 - 7s - loss: -6.0319e-01 - dice_coef: 0.6036 - val_loss: -6.1745e-01 - val_dice_coef: 0.6187
Epoch 10/100
 - 6s - loss: -6.1790e-01 - dice_coef: 0.6146 - val_loss: -6.3248e-01 - val_dice_coef: 0.6338
Epoch 11/100
 - 7s - loss: -6.0324e-01 - dice_coef: 0.6028 - val_loss: -6.1529e-01 - val_dice_coef: 0.6166
Epoch 12/100
 - 7s - loss: -6.1602e-01 - dice_coef: 0.6142 - val_loss: -6.2882e-01 - val_dice_coef: 0.6304
Epoch 13/100
 - 7s - loss: -6.0594e-01 - dice_coef: 0.6052 - val_loss: -6.0842e-01 - val_dice_coef: 0.6101
Epoch 14/100
 - 7s - loss: -6.0278e-01 - dice_coef: 0.6036 - val_loss: -6.2355e-01 - val_dice_coef: 0.6248
Epoch 15/100
 - 7s - loss: -6.2278e-01 - dice_coef: 0.6214 - val_loss: -6.1817e-01 - val_dice_coef: 0.6194
Epoch 16/100
 - 7s - loss: -6.8738e-01 - dice_coef: 0.6888 - val_loss: -7.3277e-01 - val_dice_coef: 0.7410
Epoch 17/100
 - 7s - loss: -7.7947e-01 - dice_coef: 0.7792 - val_loss: -8.2718e-01 - val_dice_coef: 0.8257
Epoch 18/100
 - 7s - loss: -8.1698e-01 - dice_coef: 0.8173 - val_loss: -8.4619e-01 - val_dice_coef: 0.8448
Epoch 19/100
 - 7s - loss: -8.5745e-01 - dice_coef: 0.8565 - val_loss: -8.8333e-01 - val_dice_coef: 0.8841
Epoch 20/100
 - 7s - loss: -8.7864e-01 - dice_coef: 0.8785 - val_loss: -9.0014e-01 - val_dice_coef: 0.9004
Epoch 21/100
 - 7s - loss: -8.9618e-01 - dice_coef: 0.8967 - val_loss: -9.1134e-01 - val_dice_coef: 0.9131
Epoch 22/100
 - 7s - loss: -9.0019e-01 - dice_coef: 0.9000 - val_loss: -8.9440e-01 - val_dice_coef: 0.8977
Epoch 23/100
 - 7s - loss: -9.1146e-01 - dice_coef: 0.9117 - val_loss: -9.2188e-01 - val_dice_coef: 0.9234
Epoch 24/100
 - 7s - loss: -9.1966e-01 - dice_coef: 0.9197 - val_loss: -9.1698e-01 - val_dice_coef: 0.9194
Epoch 25/100
 - 7s - loss: -9.1674e-01 - dice_coef: 0.9169 - val_loss: -9.2569e-01 - val_dice_coef: 0.9267
Epoch 26/100
 - 7s - loss: -9.1758e-01 - dice_coef: 0.9175 - val_loss: -9.2455e-01 - val_dice_coef: 0.9244
Epoch 27/100
 - 7s - loss: -9.2282e-01 - dice_coef: 0.9230 - val_loss: -9.2885e-01 - val_dice_coef: 0.9297
Epoch 28/100
 - 7s - loss: -9.2319e-01 - dice_coef: 0.9235 - val_loss: -9.2641e-01 - val_dice_coef: 0.9284
Epoch 29/100
 - 7s - loss: -9.2605e-01 - dice_coef: 0.9253 - val_loss: -9.2955e-01 - val_dice_coef: 0.9310
Epoch 30/100
 - 7s - loss: -9.2419e-01 - dice_coef: 0.9243 - val_loss: -9.3423e-01 - val_dice_coef: 0.9352
Epoch 31/100
 - 7s - loss: -9.2942e-01 - dice_coef: 0.9294 - val_loss: -9.3306e-01 - val_dice_coef: 0.9345
Epoch 32/100
 - 7s - loss: -9.2549e-01 - dice_coef: 0.9258 - val_loss: -9.3245e-01 - val_dice_coef: 0.9341
Epoch 33/100
 - 7s - loss: -9.3132e-01 - dice_coef: 0.9309 - val_loss: -9.3766e-01 - val_dice_coef: 0.9381
Epoch 34/100
 - 7s - loss: -9.3320e-01 - dice_coef: 0.9334 - val_loss: -9.3877e-01 - val_dice_coef: 0.9395
Epoch 35/100
 - 7s - loss: -9.3498e-01 - dice_coef: 0.9351 - val_loss: -9.2575e-01 - val_dice_coef: 0.9280
Epoch 36/100
 - 7s - loss: -9.3493e-01 - dice_coef: 0.9351 - val_loss: -9.2846e-01 - val_dice_coef: 0.9305
Epoch 37/100
 - 7s - loss: -9.3115e-01 - dice_coef: 0.9311 - val_loss: -9.3580e-01 - val_dice_coef: 0.9371
Epoch 38/100
 - 7s - loss: -9.3473e-01 - dice_coef: 0.9340 - val_loss: -9.3895e-01 - val_dice_coef: 0.9391
Epoch 39/100
 - 7s - loss: -9.3528e-01 - dice_coef: 0.9355 - val_loss: -9.3431e-01 - val_dice_coef: 0.9358
Epoch 40/100
 - 7s - loss: -9.3793e-01 - dice_coef: 0.9381 - val_loss: -9.4220e-01 - val_dice_coef: 0.9432
Epoch 41/100
 - 7s - loss: -9.3951e-01 - dice_coef: 0.9397 - val_loss: -9.3395e-01 - val_dice_coef: 0.9357
Epoch 42/100
 - 7s - loss: -9.3745e-01 - dice_coef: 0.9375 - val_loss: -9.4371e-01 - val_dice_coef: 0.9443
Epoch 43/100
 - 7s - loss: -9.3991e-01 - dice_coef: 0.9401 - val_loss: -9.4531e-01 - val_dice_coef: 0.9460
Epoch 44/100
 - 7s - loss: -9.3999e-01 - dice_coef: 0.9401 - val_loss: -9.3823e-01 - val_dice_coef: 0.9398
Epoch 45/100
 - 7s - loss: -9.4091e-01 - dice_coef: 0.9412 - val_loss: -9.4575e-01 - val_dice_coef: 0.9462
Epoch 46/100
 - 7s - loss: -9.4396e-01 - dice_coef: 0.9439 - val_loss: -9.4493e-01 - val_dice_coef: 0.9458
Epoch 47/100
 - 7s - loss: -9.4345e-01 - dice_coef: 0.9436 - val_loss: -9.4610e-01 - val_dice_coef: 0.9466
Epoch 48/100
 - 7s - loss: -9.4490e-01 - dice_coef: 0.9451 - val_loss: -9.4698e-01 - val_dice_coef: 0.9476
Epoch 49/100
 - 7s - loss: -9.4480e-01 - dice_coef: 0.9443 - val_loss: -9.3760e-01 - val_dice_coef: 0.9393
Epoch 50/100
 - 7s - loss: -9.4431e-01 - dice_coef: 0.9440 - val_loss: -9.4185e-01 - val_dice_coef: 0.9416
Epoch 51/100
 - 7s - loss: -9.4287e-01 - dice_coef: 0.9430 - val_loss: -9.4827e-01 - val_dice_coef: 0.9489
Epoch 52/100
 - 7s - loss: -9.4551e-01 - dice_coef: 0.9456 - val_loss: -9.4497e-01 - val_dice_coef: 0.9466
Epoch 53/100
 - 7s - loss: -9.4550e-01 - dice_coef: 0.9452 - val_loss: -9.4897e-01 - val_dice_coef: 0.9492
Epoch 54/100
 - 7s - loss: -9.4810e-01 - dice_coef: 0.9481 - val_loss: -9.5018e-01 - val_dice_coef: 0.9506
Epoch 55/100
 - 7s - loss: -9.4755e-01 - dice_coef: 0.9477 - val_loss: -9.4920e-01 - val_dice_coef: 0.9495
Epoch 56/100
 - 7s - loss: -9.4770e-01 - dice_coef: 0.9472 - val_loss: -9.4905e-01 - val_dice_coef: 0.9499
Epoch 57/100
 - 7s - loss: -9.4794e-01 - dice_coef: 0.9473 - val_loss: -9.5046e-01 - val_dice_coef: 0.9511
Epoch 58/100
 - 7s - loss: -9.4736e-01 - dice_coef: 0.9475 - val_loss: -9.5068e-01 - val_dice_coef: 0.9512
Epoch 59/100
 - 7s - loss: -9.4842e-01 - dice_coef: 0.9479 - val_loss: -9.4932e-01 - val_dice_coef: 0.9506
Epoch 60/100
 - 7s - loss: -9.4933e-01 - dice_coef: 0.9489 - val_loss: -9.5204e-01 - val_dice_coef: 0.9526
Epoch 61/100
 - 7s - loss: -9.4987e-01 - dice_coef: 0.9491 - val_loss: -9.4838e-01 - val_dice_coef: 0.9482
Epoch 62/100
 - 7s - loss: -9.5012e-01 - dice_coef: 0.9500 - val_loss: -9.5316e-01 - val_dice_coef: 0.9541
Epoch 63/100
 - 7s - loss: -9.4721e-01 - dice_coef: 0.9474 - val_loss: -9.5040e-01 - val_dice_coef: 0.9517
Epoch 64/100
 - 7s - loss: -9.5074e-01 - dice_coef: 0.9508 - val_loss: -9.5071e-01 - val_dice_coef: 0.9518
Epoch 65/100
 - 7s - loss: -9.5081e-01 - dice_coef: 0.9510 - val_loss: -9.5145e-01 - val_dice_coef: 0.9526
Epoch 66/100
 - 7s - loss: -9.5104e-01 - dice_coef: 0.9511 - val_loss: -9.5211e-01 - val_dice_coef: 0.9533
Epoch 67/100
 - 7s - loss: -9.4883e-01 - dice_coef: 0.9490 - val_loss: -9.5350e-01 - val_dice_coef: 0.9545
Epoch 68/100
 - 7s - loss: -9.5300e-01 - dice_coef: 0.9532 - val_loss: -9.5421e-01 - val_dice_coef: 0.9549
Epoch 69/100
 - 7s - loss: -9.5315e-01 - dice_coef: 0.9534 - val_loss: -9.5420e-01 - val_dice_coef: 0.9551
Epoch 70/100
 - 7s - loss: -9.5314e-01 - dice_coef: 0.9527 - val_loss: -9.5208e-01 - val_dice_coef: 0.9522
Epoch 71/100
 - 7s - loss: -9.5329e-01 - dice_coef: 0.9528 - val_loss: -9.5303e-01 - val_dice_coef: 0.9531
Epoch 72/100
 - 7s - loss: -9.5193e-01 - dice_coef: 0.9516 - val_loss: -9.4957e-01 - val_dice_coef: 0.9494
Epoch 73/100
 - 7s - loss: -9.5367e-01 - dice_coef: 0.9537 - val_loss: -9.5379e-01 - val_dice_coef: 0.9538
Epoch 74/100
 - 7s - loss: -9.5409e-01 - dice_coef: 0.9542 - val_loss: -9.5389e-01 - val_dice_coef: 0.9542
Epoch 75/100
 - 7s - loss: -9.5494e-01 - dice_coef: 0.9551 - val_loss: -9.5279e-01 - val_dice_coef: 0.9540
Epoch 76/100
 - 7s - loss: -9.5346e-01 - dice_coef: 0.9533 - val_loss: -9.4923e-01 - val_dice_coef: 0.9492

Epoch 00076: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.
Epoch 77/100
 - 7s - loss: -9.5547e-01 - dice_coef: 0.9552 - val_loss: -9.5564e-01 - val_dice_coef: 0.9564
Epoch 78/100
 - 7s - loss: -9.5691e-01 - dice_coef: 0.9567 - val_loss: -9.5609e-01 - val_dice_coef: 0.9570
Epoch 79/100
 - 7s - loss: -9.5742e-01 - dice_coef: 0.9570 - val_loss: -9.5595e-01 - val_dice_coef: 0.9570
Epoch 80/100
 - 7s - loss: -9.5792e-01 - dice_coef: 0.9581 - val_loss: -9.5612e-01 - val_dice_coef: 0.9570
Epoch 81/100
 - 7s - loss: -9.5807e-01 - dice_coef: 0.9583 - val_loss: -9.5534e-01 - val_dice_coef: 0.9565
Epoch 82/100
 - 7s - loss: -9.5816e-01 - dice_coef: 0.9583 - val_loss: -9.5608e-01 - val_dice_coef: 0.9570
Epoch 83/100
 - 7s - loss: -9.5817e-01 - dice_coef: 0.9578 - val_loss: -9.5626e-01 - val_dice_coef: 0.9571
Epoch 84/100
 - 7s - loss: -9.5816e-01 - dice_coef: 0.9582 - val_loss: -9.5647e-01 - val_dice_coef: 0.9573
Epoch 85/100
 - 7s - loss: -9.5858e-01 - dice_coef: 0.9587 - val_loss: -9.5627e-01 - val_dice_coef: 0.9571
Epoch 86/100
 - 7s - loss: -9.5861e-01 - dice_coef: 0.9588 - val_loss: -9.5654e-01 - val_dice_coef: 0.9574
Epoch 87/100
 - 7s - loss: -9.5893e-01 - dice_coef: 0.9583 - val_loss: -9.5640e-01 - val_dice_coef: 0.9571
Epoch 88/100
 - 7s - loss: -9.5912e-01 - dice_coef: 0.9593 - val_loss: -9.5645e-01 - val_dice_coef: 0.9574
Epoch 89/100
 - 7s - loss: -9.5902e-01 - dice_coef: 0.9592 - val_loss: -9.5655e-01 - val_dice_coef: 0.9575
Epoch 90/100
 - 7s - loss: -9.5938e-01 - dice_coef: 0.9589 - val_loss: -9.5665e-01 - val_dice_coef: 0.9576
Epoch 91/100
 - 7s - loss: -9.5948e-01 - dice_coef: 0.9586 - val_loss: -9.5681e-01 - val_dice_coef: 0.9577
Epoch 92/100
 - 7s - loss: -9.5942e-01 - dice_coef: 0.9596 - val_loss: -9.5653e-01 - val_dice_coef: 0.9575
Epoch 93/100
 - 7s - loss: -9.5953e-01 - dice_coef: 0.9597 - val_loss: -9.5679e-01 - val_dice_coef: 0.9577
Epoch 94/100
 - 7s - loss: -9.5973e-01 - dice_coef: 0.9599 - val_loss: -9.5642e-01 - val_dice_coef: 0.9575
Epoch 95/100
 - 7s - loss: -9.5985e-01 - dice_coef: 0.9596 - val_loss: -9.5641e-01 - val_dice_coef: 0.9571
Epoch 96/100
 - 7s - loss: -9.6014e-01 - dice_coef: 0.9603 - val_loss: -9.5685e-01 - val_dice_coef: 0.9577
Epoch 97/100
 - 7s - loss: -9.6024e-01 - dice_coef: 0.9603 - val_loss: -9.5669e-01 - val_dice_coef: 0.9577
Epoch 98/100
 - 7s - loss: -9.5989e-01 - dice_coef: 0.9599 - val_loss: -9.5673e-01 - val_dice_coef: 0.9574
Epoch 99/100
 - 7s - loss: -9.5997e-01 - dice_coef: 0.9601 - val_loss: -9.5691e-01 - val_dice_coef: 0.9578
Epoch 100/100
 - 7s - loss: -9.6026e-01 - dice_coef: 0.9603 - val_loss: -9.5705e-01 - val_dice_coef: 0.9579

  8/141 [>.............................] - ETA: 0s
 24/141 [====>.........................] - ETA: 0s
 40/141 [=======>......................] - ETA: 0s
 56/141 [==========>...................] - ETA: 0s
 72/141 [==============>...............] - ETA: 0s
 88/141 [=================>............] - ETA: 0s
104/141 [=====================>........] - ETA: 0s
120/141 [========================>.....] - ETA: 0s
136/141 [===========================>..] - ETA: 0s
141/141 [==============================] - 2s 12ms/step
 - test_loss: -0.9559655092286725 - test_dice_coef: 0.9560571312904358
